### [Using Llama 3.1 405B to train Roberta-base 125M](https://github.com/ALucek/LLM-distillation-guide/blob/main/model_distillation.ipynb)
